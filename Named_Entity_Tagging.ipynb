{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_30_A2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs7nX5_FdVb1",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as0mikmalohM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6fdf0b52-4eb4-4b53-dd9d-b47ae4bd0dec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRh3I_YamfK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0382dd59-2a93-49a3-8245-2e58a869320c"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from gensim.models import Word2Vec\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pprint\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_KT9jEmNEEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_CRmCacdeoq",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrbebecemhdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55ea3f08-df4e-4fb1-9fb1-4d15a9e810c5"
      },
      "source": [
        "%%time \n",
        "path = '/content/gdrive/My Drive/COMP5046/Assignment2'\n",
        "file_name = '2020-comp5046-a2.zip'\n",
        "\n",
        "with ZipFile(path + '/' + file_name, 'r') as z:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   z.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.89 ms, sys: 2.53 ms, total: 8.42 ms\n",
            "Wall time: 3.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEzs6Baimti2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(os.getcwd() + '/train.csv') #30,000 for training \n",
        "df_valid = pd.read_csv(os.getcwd() + '/val.csv') #10,000 for testing \n",
        "df_test = pd.read_csv(os.getcwd() + '/test.csv') #10,000 for testing "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOyVoN9znDM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1fcdf643-78eb-45de-f2d0-542d468168e9"
      },
      "source": [
        "print(df_train.shape)\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-docstart-</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>soccer - japan get lucky win , china in surpri...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nadim ladki</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>al-ain , united arab emirates 1996-12-06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>japan began the defence of their asian cup tit...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  NER\n",
              "0                                         -docstart-  NaN\n",
              "1  soccer - japan get lucky win , china in surpri...  NaN\n",
              "2                                        nadim ladki  NaN\n",
              "3           al-ain , united arab emirates 1996-12-06  NaN\n",
              "4  japan began the defence of their asian cup tit...  NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Zzr9kGrrVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences_and_labels(df, get_labels = True): \n",
        "    \"\"\"\n",
        "    Get a list of sentences and labels\n",
        "    \"\"\"\n",
        "    sentences, labels = [], []\n",
        "\n",
        "    for sent in df['Sentence'].tolist():\n",
        "        sentences.append(sent.split(' '))\n",
        "\n",
        "    if get_labels == True: \n",
        "        for sent_labels in df['NER'].tolist(): \n",
        "            labels.append(sent_labels.split(' '))\n",
        "\n",
        "    return sentences, labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtZ1ilYtTue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d5c82ec1-2f53-46ec-c844-94545089853d"
      },
      "source": [
        "%%time \n",
        "X_train, y_train = get_sentences_and_labels(df_train)\n",
        "X_valid, y_valid = get_sentences_and_labels(df_valid)\n",
        "X_test, _ = get_sentences_and_labels(df_test, get_labels = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.3 ms, sys: 2.84 ms, total: 13.2 ms\n",
            "Wall time: 13.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV4_wLexdkYU",
        "colab_type": "text"
      },
      "source": [
        "## Create Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyciipFpVy2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b5f7c38a-5571-4fa1-a9e2-3d9eb679eb64"
      },
      "source": [
        "### get unique words and assign an index to each word \n",
        "%%time\n",
        "\n",
        "all_sentences = X_train + X_valid + X_test\n",
        "\n",
        "word_to_idx = {} #this stores the vocabulary \n",
        "for sent in all_sentences:\n",
        "    for word in sent: \n",
        "        if word not in word_to_idx:\n",
        "            word_to_idx[word] = len(word_to_idx)\n",
        "print('Vocab size:', len(word_to_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 13972\n",
            "CPU times: user 14.8 ms, sys: 0 ns, total: 14.8 ms\n",
            "Wall time: 15.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_ggddADDeu",
        "colab_type": "text"
      },
      "source": [
        "### Encode named entity tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0_pDxlSgHIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "db0e99d8-b3b4-4ff6-8137-045694a9a7a2"
      },
      "source": [
        "### get unique named entities and assign an index to each tag\n",
        "%%time \n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_idx = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in y_train + y_valid:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_idx:\n",
        "            tag_to_idx[tag] = len(tag_to_idx)\n",
        "\n",
        "print('Named entities: ', tag_to_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Named entities:  {'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n",
            "CPU times: user 5.47 ms, sys: 318 µs, total: 5.79 ms\n",
            "Wall time: 6.44 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdjgYfGcDKMm",
        "colab_type": "text"
      },
      "source": [
        "### Encode POS tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkAvZKKPI3mL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "070c7c8c-c7eb-4769-87a2-0c03dea957b7"
      },
      "source": [
        "### get unique pos tags and assign an index to each tag \n",
        "%%time \n",
        "postag_to_idx = {} \n",
        "for sent in all_sentences: \n",
        "    for word in sent: \n",
        "        tag = nltk.pos_tag([word])[0][1] \n",
        "        if tag not in postag_to_idx: \n",
        "            postag_to_idx[tag] = len(postag_to_idx)\n",
        "print('Number of POS tags: ', len(postag_to_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of POS tags:  34\n",
            "CPU times: user 7.49 s, sys: 470 ms, total: 7.96 s\n",
            "Wall time: 7.97 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mitlbR1eDM-V",
        "colab_type": "text"
      },
      "source": [
        "### Encode dependency tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_opDDY8ARfMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dep_to_idx  = {'ROOT': 0, 'nsubj': 1, 'amod': 2, 'dobj': 3, 'aux': 4, 'acl': 5, \n",
        "               'punct': 6, 'compound': 7, 'npadvmod': 8, 'nummod': 9, 'det': 10, \n",
        "               'prep': 11, 'pobj': 12, 'ccomp': 13, 'advcl': 14, 'mark': 15, \n",
        "               'nsubjpass': 16, 'auxpass': 17, 'poss': 18, 'case': 19, 'acomp': 20, \n",
        "               'neg': 21, 'cc': 22, 'conj': 23, 'agent': 24, 'advmod': 25, 'attr': 26, \n",
        "               'appos': 27, 'xcomp': 28,'expl': 29, 'pcomp': 30, 'dep': 31, \n",
        "               'relcl': 32, 'csubj': 33, 'nmod': 34, 'prt': 35, 'quantmod': 36, \n",
        "               'parataxis': 37, 'oprd': 38, 'dative': 39, 'intj': 40, 'preconj': 41, \n",
        "               'predet': 42, 'meta': 43}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgvDUp5JGjpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "def get_dependency_info(sentence, dep_to_idx):\n",
        "    \"\"\"\n",
        "    Get the dependency labels from dependency parsing for \n",
        "    each word in the given sentence. \n",
        "    \"\"\"\n",
        "    parse = nlp(' '.join(sentence))\n",
        "    pred_dep = [t.dep_ for i, t in enumerate(parse)]\n",
        "\n",
        "    dependencies = [] #stores the dependency labels \n",
        "\n",
        "    for dep_label in pred_dep:\n",
        "     \n",
        "        dependencies.append(dep_to_idx[dep_label])\n",
        "\n",
        "    return dependencies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGauXnb_DRbO",
        "colab_type": "text"
      },
      "source": [
        "### Encode suffix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuhrgv9kloLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dc971c4-b3d7-464c-b2b4-2ab916125332"
      },
      "source": [
        "### get unique suffixes and assign an index to each suffix \n",
        "\n",
        "SUFFIX_LEN = 3\n",
        "\n",
        "suffix_to_idx = {} \n",
        "for sent in all_sentences:\n",
        "    for word in sent: \n",
        "        if word[-SUFFIX_LEN:] not in suffix_to_idx: \n",
        "            suffix_to_idx[word[-SUFFIX_LEN:]] = len(suffix_to_idx)\n",
        "print('Number of unique suffixes: ', len(suffix_to_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique suffixes:  3494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54-uHHoL27E",
        "colab_type": "text"
      },
      "source": [
        "### Collect tf-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um-GpTw4MT_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE9VanKNN2W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### accumulate documents \n",
        "all_documents = [] \n",
        "doc = []\n",
        "sent_to_doc_id = {} \n",
        "\n",
        "for sent in all_sentences: \n",
        "    if sent[0] == '-docstart-':\n",
        "        all_documents.append(doc)\n",
        "        doc = []\n",
        "    doc.append(' '.join(sent))\n",
        "    sent_to_doc_id[' '.join(sent)] = len(all_documents)-1\n",
        "\n",
        "all_documents.append(doc)\n",
        "all_documents = all_documents[1:]\n",
        "all_documents = [' '.join(x) for x in all_documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx9F8Ps3Vjbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af443bfa-ed1b-4137-e356-d6e59cba6a6d"
      },
      "source": [
        "print('Number of documents: ', len(all_documents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents:  454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuqw6on37_q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "914ca17a-866e-4559-a1cc-5da660447ed6"
      },
      "source": [
        "def white_space_tokenizer(s):\n",
        "   return s.split(' ')\n",
        "\n",
        "corpus = all_documents\n",
        "vectorizer = TfidfVectorizer(tokenizer = white_space_tokenizer)\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "tfidf_matrix = tfidf_matrix.toarray()\n",
        "tfidf_matrix.shape #shape = (number of documents, vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(454, 13972)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6HrPaTEH72W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28fd6afe-fc13-4902-c83d-ebbff6941125"
      },
      "source": [
        "features_arr = vectorizer.get_feature_names()\n",
        "features_to_idx = {n: i for i, n in enumerate(features_arr)}\n",
        "features_to_idx['fun']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6531"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_OpNyatLI5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_features(all_sentences, min_i, max_i):\n",
        "    \"\"\"\n",
        "    Return the tf-idf for each word in each document. \n",
        "    \"\"\"\n",
        "    tfidf_features = []\n",
        "\n",
        "    for i in range(min_i, max_i): \n",
        "\n",
        "        sentence = all_sentences[i]\n",
        "        joined_sentence = ' '.join(sentence)\n",
        "        doc_id = sent_to_doc_id[joined_sentence] \n",
        "        temp = []\n",
        "\n",
        "        for word in sentence: \n",
        "            word_id = features_to_idx[word]\n",
        "            tfidf = tfidf_matrix[doc_id][word_id]\n",
        "            temp.append(tfidf)\n",
        "            \n",
        "        tfidf_features.append(temp)\n",
        "\n",
        "    return tfidf_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG_hmz_7Utrn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bb45b7a7-f9b4-4c55-8baa-7962ce17cbbe"
      },
      "source": [
        "print('Number of training sentences: ', len(X_train))\n",
        "print('Number of validation sentences: ', len(X_valid))\n",
        "print('Number of testing sentences: ', len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences:  3000\n",
            "Number of validation sentences:  700\n",
            "Number of testing sentences:  3684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuS0hznOMp-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "766ed897-0c21-4a0a-d1bf-f9c8d5898eb6"
      },
      "source": [
        "%%time \n",
        "train_tfidf = get_tfidf_features(all_sentences, 0, 3000)\n",
        "valid_tfidf = get_tfidf_features(all_sentences, 3000, 3700)\n",
        "test_tfidf = get_tfidf_features(all_sentences, 3700, 7384)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 52.1 ms, sys: 3.62 ms, total: 55.7 ms\n",
            "Wall time: 60.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRj46fCrJV_O",
        "colab_type": "text"
      },
      "source": [
        "### Character-based embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdrkwOqq0GQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f12870e-8c86-4ad7-c25d-584b9cfc8a97"
      },
      "source": [
        "!pip install chars2vec -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.1MB 34.1MB/s \n",
            "\u001b[?25h  Building wheel for chars2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGDq-9aKIsMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6a20b0da-b092-4362-b2de-230d3073526e"
      },
      "source": [
        "%%time\n",
        "import chars2vec\n",
        "c2v_model = chars2vec.load_model('eng_50')\n",
        "\n",
        "words = list(word_to_idx.keys())\n",
        "# Create word embeddings\n",
        "char_based_embeddings = c2v_model.vectorize_words(words)\n",
        "print(char_based_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(13972, 50)\n",
            "CPU times: user 12.6 s, sys: 2.16 s, total: 14.8 s\n",
            "Wall time: 28.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK68rxb5L35v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_char_embeddings(sentences):\n",
        "    \"\"\"\n",
        "    Function to get character-level embedding for each word\n",
        "    in given sentence. \n",
        "    \"\"\"\n",
        "    char_embedded_sentences = []\n",
        "    for sent in sentences:\n",
        "        temp = []\n",
        "        for word in sent: \n",
        "            idx = word_to_idx[word]\n",
        "            temp.append(char_based_embeddings[idx])\n",
        "        char_embedded_sentences.append(temp)\n",
        "        \n",
        "    return np.array(char_embedded_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVNQWR9NcHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ab4647d-d3cd-4c9d-968f-deea3c0aeddc"
      },
      "source": [
        "%%time \n",
        "train_char_embeddings = get_char_embeddings(X_train)\n",
        "valid_char_embeddings = get_char_embeddings(X_valid)\n",
        "test_char_embeddings = get_char_embeddings(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 34 ms, sys: 3.84 ms, total: 37.8 ms\n",
            "Wall time: 38.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjQ5Y0pqEsZp",
        "colab_type": "text"
      },
      "source": [
        "### Collect other features (pos tag, dependency tag, suffix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pxdCc6jfdZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_idx, feature = None):\n",
        "    \"\"\"\n",
        "    Converts the features to corresponding indexes. \n",
        "    \"\"\"\n",
        "    input_index_list = []\n",
        "\n",
        "    if feature == 'postag': \n",
        "        for sent in data:\n",
        "            input_index_list.append([to_idx[nltk.pos_tag([w])[0][1]] for w in sent])\n",
        "    elif feature == 'dependency': \n",
        "        for sent in data:\n",
        "            input_index_list.append(get_dependency_info(sent, to_idx))\n",
        "    elif feature == 'suffix': \n",
        "        for sent in data: \n",
        "            input_index_list.append([to_idx[w[-3:]] for w in sent])\n",
        "    else: \n",
        "        for sent in data:\n",
        "            input_index_list.append([to_idx[w] for w in sent])\n",
        "\n",
        "    return input_index_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0vlFL2dc4Xy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dee2f167-c45d-4476-b86f-ef2304b9e9c2"
      },
      "source": [
        "%%time \n",
        "train_sentence_index =  to_index(X_train, word_to_idx)\n",
        "train_postag_index = to_index(X_train, postag_to_idx, feature = 'postag')\n",
        "train_dep_index = to_index(X_train, dep_to_idx, feature = 'dependency')\n",
        "train_suffix_index = to_index(X_train, suffix_to_idx, feature = 'suffix')\n",
        "\n",
        "train_output_index = to_index(y_train, tag_to_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.7 s, sys: 283 ms, total: 23.9 s\n",
            "Wall time: 24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QXpOE04hnga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "09892e4b-592d-4805-9030-0150a3c8c72c"
      },
      "source": [
        "%%time \n",
        "valid_sentence_index =  to_index(X_valid, word_to_idx)\n",
        "valid_postag_index = to_index(X_valid, postag_to_idx, feature = 'postag')\n",
        "valid_dep_index = to_index(X_valid, dep_to_idx, feature = 'dependency')\n",
        "valid_suffix_index = to_index(X_valid, suffix_to_idx, feature = 'suffix')\n",
        "\n",
        "valid_output_index = to_index(y_valid, tag_to_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.09 s, sys: 64.6 ms, total: 5.15 s\n",
            "Wall time: 5.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de6T8FNmhIol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "868b01ce-3f79-41d1-9026-96f6b912ef07"
      },
      "source": [
        "%%time \n",
        "test_sentence_index =  to_index(X_test, word_to_idx)\n",
        "test_postag_index = to_index(X_test, postag_to_idx, feature = 'postag')\n",
        "test_dep_index = to_index(X_test, dep_to_idx, feature = 'dependency')\n",
        "test_suffix_index = to_index(X_test, suffix_to_idx, feature = 'suffix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.9 s, sys: 242 ms, total: 28.1 s\n",
            "Wall time: 28.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-0FJrG5W7b5",
        "colab_type": "text"
      },
      "source": [
        "### Pack all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02o5GMUxR2P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack_features(sentence_index, postag_index, dep_index, suffix_index, tfidf_seq, char_embeds):\n",
        "    \"\"\"\n",
        "    Accumulate all used features into a dictionary. \n",
        "    \"\"\"\n",
        "    input_dict = {'sentence': sentence_index,\n",
        "                    'pos': postag_index,\n",
        "                    'dep': dep_index,\n",
        "                    'suffix': suffix_index,\n",
        "                    'tfidf':tfidf_seq,\n",
        "                    'char embed': char_embeds}\n",
        "\n",
        "    return input_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez2adgH-SjlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e6bfd5c-4d33-4c30-cbb4-6fa43d7d31c5"
      },
      "source": [
        "%%time \n",
        "train_input_dict = pack_features(train_sentence_index, train_postag_index, train_dep_index,\n",
        "                                 train_suffix_index, train_tfidf, train_char_embeddings)\n",
        "valid_input_dict = pack_features(valid_sentence_index, valid_postag_index, valid_dep_index,\n",
        "                                 valid_suffix_index, valid_tfidf, valid_char_embeddings)\n",
        "test_input_dict = pack_features(test_sentence_index, test_postag_index, test_dep_index,\n",
        "                                 test_suffix_index, test_tfidf, test_char_embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
            "Wall time: 11.9 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3VJo1832zLb",
        "colab_type": "text"
      },
      "source": [
        "## Create Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmD6rf3323gK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2235d083-1f23-48b3-fe39-d02b5fbc39e6"
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-100\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[============================================------] 88.9% 344.2/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCTrmL6d28zy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "612e8867-17f1-485c-b7e5-b9146a05435d"
      },
      "source": [
        "### The embedding matrix will be the initial weights of the embedding layer in the network.\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in list(word_to_idx.keys()):\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "print('Shape of embedding matrix: ', embedding_matrix.shape) #shape = (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of embedding matrix:  (13972, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k_wy3OGS9vV",
        "colab_type": "text"
      },
      "source": [
        "## Build NER Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGlROATp-Onb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### define some global variables \n",
        "VOCAB_SIZE = len(word_to_idx)\n",
        "DEP_SIZE = len(dep_to_idx)\n",
        "POS_SIZE = len(postag_to_idx)\n",
        "SUFFIX_SIZE = len(suffix_to_idx)\n",
        "\n",
        "\n",
        "WORD_EMB_DIM = EMBEDDING_DIM\n",
        "CHAR_EMB_DIM = 50\n",
        "DEP_EMB_DIM = 20\n",
        "POS_EMB_DIM = 20\n",
        "SUFFIX_EMB_DIM = 20\n",
        "TFIDF_EMB_DIM = 50\n",
        "\n",
        "FINAL_EMB_DIM = WORD_EMB_DIM + POS_EMB_DIM + DEP_EMB_DIM\n",
        "\n",
        "OUTPUT_DIM = len(tag_to_idx)\n",
        "\n",
        "NUM_LAYERS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSqzySKXQ5tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax(vector):\n",
        "    \"\"\"\n",
        "    Get index position of maximum value in vector.\n",
        "    \"\"\"\n",
        "    _, idx = torch.max(vector, 1)\n",
        "    return idx.item()\n",
        "\n",
        "def log_sum_exp(vector): \n",
        "    \"\"\"\n",
        "    Given tensor, calculates log of the sum of exponentials\n",
        "    \"\"\"\n",
        "    ### input vector has shape (1, 7)\n",
        "    max_score = vector[0, argmax(vector)] \n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vector.size()[1]) #shape = (1, 7)\n",
        "\n",
        "    return max_score + torch.log(torch.sum(torch.exp(vector - max_score_broadcast)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9cFCpjVTAMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, hidden_dim, tag_to_idx, attn_method = None): \n",
        "        super(BiLSTM_CRF, self).__init__() \n",
        "\n",
        "        # some class variables \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.tag_to_idx = tag_to_idx \n",
        "        self.attn_method = attn_method\n",
        "        \n",
        "        # initialise embedding layers \n",
        "        self.word_embedding = nn.Embedding(VOCAB_SIZE, WORD_EMB_DIM)\n",
        "        self.word_embedding.weight.data.copy_(torch.from_numpy(embedding_matrix)) #set initial weights to glove weights\n",
        "        self.pos_embedding = nn.Embedding(POS_SIZE, POS_EMB_DIM)\n",
        "        self.dep_embedding = nn.Embedding(DEP_SIZE, DEP_EMB_DIM)\n",
        "        #self.suffix_embedding = nn.Embedding(SUFFIX_SIZE, SUFFIX_EMB_DIM)\n",
        "\n",
        "        # Feed embedding to LSTM layers \n",
        "        self.lstm = nn.LSTM(FINAL_EMB_DIM, hidden_dim // 2, num_layers = NUM_LAYERS,\n",
        "                            bidirectional = True, dropout = 0.40)\n",
        "        \n",
        "        #self.lstm_tfidf = nn.LSTM(1, TFIDF_EMB_DIM, num_layers = 1, bidirectional = False)\n",
        "\n",
        "        # Map output of lstm to tag space \n",
        "        self.hidden_to_tag_attn = nn.Linear(2*hidden_dim, OUTPUT_DIM)\n",
        "        #self.hidden_to_tag_attn = nn.Linear(2*(hidden_dim + TFIDF_EMB_DIM), OUTPUT_DIM)\n",
        "        #self.hidden_to_tag = nn.Linear(hidden_dim + TFIDF_EMB_DIM, OUTPUT_DIM)\n",
        "        #self.hidden_to_tag = nn.Linear(hidden_dim, OUTPUT_DIM)\n",
        "\n",
        "        #initialise transition matrix as part of model parameters.\n",
        "        #Entry (i,j) = score transitioning to i from j. \n",
        "        self.transitions = nn.Parameter(torch.randn(OUTPUT_DIM, OUTPUT_DIM))\n",
        "\n",
        "        #enforce some transition tules \n",
        "        self.transitions.data[tag_to_idx[START_TAG], :] = -10000 # we never transfer to start tag\n",
        "        self.transitions.data[:, tag_to_idx[STOP_TAG]] = -10000 # we never transfer from stop tag \n",
        "\n",
        "        self.hidden = self.init_hidden() #randomly initialise hidden state \n",
        "        #self.hidden_tfidf = self.init_hidden_tfidf()\n",
        "\n",
        "        #self.Whc = nn.Linear(hidden_dim + TFIDF_EMB_DIM, hidden_dim + TFIDF_EMB_DIM) #need to adjust this \n",
        "        #self.Whc = nn.Linear(hidden_dim, hidden_dim) #need to adjust this \n",
        "\n",
        "    def init_hidden(self): \n",
        "        ### shape = (num of dir * num of layers, batch size, hidden_dim)\n",
        "        return (torch.randn(2 * NUM_LAYERS, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2 * NUM_LAYERS, 1, self.hidden_dim // 2).to(device))\n",
        "        \n",
        "    def init_hidden_tfidf(self): \n",
        "        return (torch.randn(1, 1, TFIDF_EMB_DIM).to(device),\n",
        "                torch.randn(1, 1, TFIDF_EMB_DIM).to(device))\n",
        "\n",
        "    def forward_alg(self, features): \n",
        "        # takes in the output from the last linear layer. Has shape = (sentence_len, OUTPUT_DIM)\n",
        "        # intial = initial scores of transitioning to a hidden state (tags)\n",
        "        initial = torch.full((1, OUTPUT_DIM), -10000.).to(device) #shape = (1, 7)\n",
        "        initial[0][self.tag_to_idx[START_TAG]] = 0 #give start tag all the score \n",
        "\n",
        "        forward_var = initial \n",
        "\n",
        "        for f in features:  #for each feature corresponding to each word in the sentence\n",
        "            alphas_t = [] #holds the log_sum_exps for this step \n",
        "            for next_tag in range(OUTPUT_DIM): \n",
        "                \n",
        "                # emission score = score of transitioning to observed state (outputs) condition on hidden state (tags)\n",
        "                emission_score = f[next_tag].view(1,-1).expand(1, OUTPUT_DIM) # shape = (1, 7)\n",
        "                # transition score = score for transitioning to next tag from i'th tag.  \n",
        "                transition_score = self.transitions[next_tag].view(1, -1) #shape = (1, 7)\n",
        "                next_tag_var = forward_var + transition_score + emission_score #shape = (1, 7)\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1)) \n",
        "            \n",
        "            forward_var = torch.cat(alphas_t).view(1, -1) # concatenate tensors in list: shape = (1, 9)\n",
        "        \n",
        "        # add stop tag and calculate log sum of exps again \n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_idx[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def calculate_attention(self, encoder_out, final_hidden):\n",
        "        \n",
        "        #encoder_out has shape = (1, num_seq, hidden_dim)\n",
        "        hidden = final_hidden.squeeze(0) #shape = (1, hidden_dim)\n",
        "        \n",
        "        #attn_score should have shape (1, seq_len)\n",
        "        if self.attn_method == ATTN_TYPE_DOT_PRODUCT: \n",
        "            attn_score = torch.bmm(encoder_out, hidden.unsqueeze(2)).squeeze(2)\n",
        "            \n",
        "        if self.attn_method == ATTN_TYPE_SCALE_DOT_PRODUCT: \n",
        "            n = hidden.shape[1]\n",
        "            attn_score = 1/np.sqrt(n) * torch.bmm(encoder_out, hidden.unsqueeze(2)).squeeze(2) \n",
        "            \n",
        "        if self.attn_method == ATTN_TYPE_GENERAL: \n",
        "            #multiply hidden state by weight matrix\n",
        "            attn_score = torch.bmm(encoder_out, self.Whc(hidden).unsqueeze(2)).squeeze(2) \n",
        "\n",
        "        if self.attn_method == ATTN_TYPE_CONTENT_BASED: \n",
        "            cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "            attn_score = cos(encoder_out[0], hidden).view(1, encoder_out.shape[1])\n",
        "\n",
        "        soft_attn_weights = F.softmax(attn_score, dim = 1) #shape = (1, seq_len)\n",
        "        attn_output = torch.bmm(encoder_out.transpose(1,2), soft_attn_weights.unsqueeze(2)).squeeze(2) #shape = (1, hidden_dim)\n",
        "        #concatenate attention output with current hidden state. shape = (1, hidden_dim * 2)\n",
        "        concat_out = torch.cat((attn_output, hidden), 1)\n",
        "\n",
        "        return concat_out\n",
        "\n",
        "    def get_lstm_features(self, input): \n",
        "        \n",
        "        # gather features \n",
        "        sentence_idxs = input['sentence']\n",
        "        pos_idxs = input['pos']\n",
        "        dep_idxs = input['dep']\n",
        "        # suffix_idxs = input['suffix']\n",
        "        # tfidf_feats = input['tfidf'] #shape = seq_len \n",
        "        # tfidf_feats = tfidf_feats.view(len(tfidf_feats), 1, -1)\n",
        "        # char_embeds = input['char embed']\n",
        "        # char_embeds = char_embeds.view(len(char_embeds), 1, -1)\n",
        "\n",
        "        #initialise hidden states\n",
        "        self.hidden = self.init_hidden() \n",
        "        self.hidden_tfidf = self.init_hidden_tfidf()\n",
        "\n",
        "        # get embeddings \n",
        "        word_embeds = self.word_embedding(sentence_idxs).view(len(sentence_idxs), 1, -1)\n",
        "        pos_embeds = self.pos_embedding(pos_idxs).view(len(pos_idxs), 1, -1)\n",
        "        dep_embeds = self.dep_embedding(dep_idxs).view(len(dep_idxs), 1, -1)\n",
        "        #suffix_embeds = self.suffix_embedding(suffix_idxs).view(len(suffix_idxs), 1, -1)\n",
        "\n",
        "        # concatenate embeddings: shape = (seq_len, 1, FINAL_DIM)\n",
        "        final_embeds = torch.cat([word_embeds, pos_embeds, dep_embeds], dim = 2)\n",
        "        #final_embeds = word_embeds\n",
        "\n",
        "        #feed through lstm layer \n",
        "        lstm_out, self.hidden = self.lstm(final_embeds, self.hidden) #lstm_out shape = (seq_len, 1, hidden_dim)\n",
        "       \n",
        "        #lstm_tfidf_out, self.hidden_tfidf = self.lstm_tfidf(tfidf_feats, self.hidden_tfidf) #shape = (seq_len, 1, 20)\n",
        "        #lstm_out = torch.cat((lstm_out, lstm_tfidf_out), dim = 2) #70\n",
        "\n",
        "        if self.attn_method is not None: #use attention\n",
        "\n",
        "            context_vectors = [] #stores attention outputs for each hidden state at timestep t\n",
        "            encoder_states = lstm_out.permute(1, 0, 2) #shape = (1, num_seq, hidden_size)\n",
        "\n",
        "            for timestep in range(0, len(sentence_idxs)): \n",
        "                current_state = lstm_out[timestep,:,:].unsqueeze(0) #get hidden state at timestep t. shape = (1, hidden_dim)\n",
        "                attn_out = self.calculate_attention(encoder_states, current_state) #calculate attn for this hidden state\n",
        "                context_vectors.append(attn_out)\n",
        "            \n",
        "            #concatenate all attention scores for each decoder hidden state \n",
        "            final_out = torch.cat(context_vectors, dim = 0) #shape = (seq_len, hidden_dim * 2)\n",
        "            #final_out = final_out.view(len(sentence_idxs), (self.hidden_dim + TFIDF_EMB_DIM) * 2)\n",
        "            final_out = final_out.view(len(sentence_idxs), self.hidden_dim * 2)\n",
        "            lstm_features = self.hidden_to_tag_attn(final_out)\n",
        "        \n",
        "        else: \n",
        "            #final_out = lstm_out.view(len(sentence_idxs), self.hidden_dim + TFIDF_EMB_DIM) #reshape to (seq_len, hidden_dim)\n",
        "            final_out = lstm_out.view(len(sentence_idxs), self.hidden_dim)\n",
        "            lstm_features = self.hidden_to_tag(final_out) #shape = (seq_len, OUTPUT_DIM)\n",
        "     \n",
        "        return lstm_features\n",
        "\n",
        "    def score_sentence(self, features, tags): \n",
        "        \"\"\"\n",
        "        Function to calculate the ground truth loss. \n",
        "        \"\"\"\n",
        "        score = torch.zeros(1).to(device)\n",
        "        #tags is a tensor of indexes for named entity tags \n",
        "        tags = torch.cat([torch.tensor([self.tag_to_idx[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        \n",
        "        for i, f in enumerate(features): #iterate through sentence features \n",
        "            #score = transition score + emission score \n",
        "            score += self.transitions[tags[i + 1], tags[i]] + f[tags[i + 1]]\n",
        "\n",
        "        #consider score from transition to last tag to stop tag as well. \n",
        "        score +=  self.transitions[self.tag_to_idx[STOP_TAG], tags[-1]]\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def viterbi(self, features): \n",
        "\n",
        "        #initialise viterbi variables \n",
        "        initial_vvars = torch.full((1, OUTPUT_DIM), -10000.).to(device)\n",
        "        initial_vvars[0][self.tag_to_idx[START_TAG]] = 0 \n",
        "\n",
        "        forward_var = initial_vvars \n",
        "        backpointers = []\n",
        "\n",
        "        for feat in features: \n",
        "            #holds the backpointers and viterbi variables for this time step\n",
        "            bp_t, viterbivars_t = [], []\n",
        "\n",
        "            for next_tag in range(OUTPUT_DIM): \n",
        "\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bp_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "\n",
        "            # Add emission scores. viterbivars_t and f has length 9\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1) #shape = (1, 9)\n",
        "            backpointers.append(bp_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_idx[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Backtrack to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bp_t in reversed(backpointers):\n",
        "            best_tag_id = bp_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag \n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_idx[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "\n",
        "        return path_score, best_path\n",
        "\n",
        "\n",
        "    def neg_log_likelihood(self, input, tags):\n",
        "        \"\"\"\n",
        "        Self defined loss function. \n",
        "        \"\"\"\n",
        "        # tags = ground truth tags \n",
        "\n",
        "        features = self.get_lstm_features(input)\n",
        "        forward_score = self.forward_alg(features)\n",
        "        gold_score = self.score_sentence(features, tags)\n",
        "\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, input):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_features = self.get_lstm_features(input)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_sequence = self.viterbi(lstm_features)\n",
        "\n",
        "        return score, tag_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbU3Gty9vpYl",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB0bBCZMvo81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100 #has to be even number \n",
        "EPOCHS = 25\n",
        "\n",
        "# attention types \n",
        "ATTN_TYPE_DOT_PRODUCT = \"dot product\"\n",
        "ATTN_TYPE_SCALE_DOT_PRODUCT = \"scaled dot product\"\n",
        "ATTN_TYPE_GENERAL = 'general'\n",
        "ATTN_TYPE_CONTENT_BASED = 'cosine'\n",
        "\n",
        "model = BiLSTM_CRF(HIDDEN_DIM, tag_to_idx, ATTN_TYPE_DOT_PRODUCT).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06SmfSNk_6Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load trained model \n",
        "model = torch.load('final_model.pt')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upy8yN3Q0yAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpack_features(index, input_dict): \n",
        "    \"\"\"\n",
        "    Creates a dictionary of input features to be fed into the model. \n",
        "    \"\"\"\n",
        "    input = {'sentence': torch.tensor(input_dict['sentence'][index], dtype=torch.long).to(device),\n",
        "              'pos': torch.tensor(input_dict['pos'][index], dtype=torch.long).to(device),\n",
        "              'dep': torch.tensor(input_dict['dep'][index], dtype=torch.long).to(device)}\n",
        "            # 'suffix': torch.tensor(input_dict['suffix'][index], dtype=torch.long).to(device),\n",
        "            # 'tfidf':torch.tensor(input_dict['tfidf'][index], dtype=torch.float).to(device),\n",
        "            # 'char embed':torch.tensor(input_dict['char embed'][index], dtype=torch.float).to(device)}\n",
        "\n",
        "    return input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aJD19N_z2Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_acc(model, input_dict, output_index):\n",
        "    \"\"\"\n",
        "    Function to calculates the prediction accuracy of the current model. \n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    ground_truth, predicted = [], []\n",
        "\n",
        "    for i in range(0, len(input_dict['sentence'])): \n",
        "        \n",
        "        input = unpack_features(i, input_dict)\n",
        "        predictions = model(input)[1] #predictions are 2nd element of tuple \n",
        "        \n",
        "        predicted += predictions\n",
        "        ground_truth += output_index[i]\n",
        "\n",
        "        for j in range(0, len(predictions)):\n",
        "            if predictions[j] == output_index[i][j]:\n",
        "                accuracy += 1\n",
        "    \n",
        "    accuracy = accuracy/len(predicted)\n",
        "\n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMcIS1KNwLd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "a2ab4744-ae56-4ac0-e7d7-17b1c4d8ee94"
      },
      "source": [
        "import datetime\n",
        "\n",
        "train_losses, valid_losses = [], []\n",
        "train_accs, valid_accs = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):  \n",
        "\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i in range(0, len(train_sentence_index)):\n",
        "    \n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        train_input = unpack_features(i, train_input_dict)\n",
        "        model.zero_grad()\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        " \n",
        "        loss = model.neg_log_likelihood(train_input, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    _, _, train_acc = cal_acc(model, train_input_dict, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model, valid_input_dict, valid_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i in range(0, len(valid_sentence_index)):\n",
        "        tags_index = valid_output_index[i]\n",
        "\n",
        "        valid_input = unpack_features(i, valid_input_dict)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(valid_input, targets)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    #store losses and accuracies \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_accs.append(val_acc)\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 11549.15, train acc: 0.9212, val loss: 1589.41, val acc: 0.9222, time: 239.06s\n",
            "Epoch:2, Training loss: 6368.89, train acc: 0.9376, val loss: 1394.02, val acc: 0.9285, time: 238.42s\n",
            "Epoch:3, Training loss: 5013.22, train acc: 0.9520, val loss: 1188.85, val acc: 0.9412, time: 239.57s\n",
            "Epoch:4, Training loss: 3971.94, train acc: 0.9544, val loss: 1256.31, val acc: 0.9423, time: 243.25s\n",
            "Epoch:5, Training loss: 3314.97, train acc: 0.9623, val loss: 1192.20, val acc: 0.9504, time: 246.47s\n",
            "Epoch:6, Training loss: 2724.22, train acc: 0.9685, val loss: 1169.89, val acc: 0.9512, time: 242.83s\n",
            "Epoch:7, Training loss: 2322.53, train acc: 0.9732, val loss: 1176.53, val acc: 0.9508, time: 244.92s\n",
            "Epoch:8, Training loss: 1918.65, train acc: 0.9749, val loss: 1266.55, val acc: 0.9513, time: 244.69s\n",
            "Epoch:9, Training loss: 1621.39, train acc: 0.9798, val loss: 1216.86, val acc: 0.9533, time: 244.30s\n",
            "Epoch:10, Training loss: 1367.04, train acc: 0.9786, val loss: 1329.86, val acc: 0.9513, time: 244.48s\n",
            "Epoch:11, Training loss: 1174.35, train acc: 0.9838, val loss: 1402.94, val acc: 0.9563, time: 241.35s\n",
            "Epoch:12, Training loss: 1058.35, train acc: 0.9870, val loss: 1307.10, val acc: 0.9608, time: 244.23s\n",
            "Epoch:13, Training loss: 961.72, train acc: 0.9889, val loss: 1316.96, val acc: 0.9599, time: 244.90s\n",
            "Epoch:14, Training loss: 870.49, train acc: 0.9915, val loss: 1324.43, val acc: 0.9628, time: 243.35s\n",
            "Epoch:15, Training loss: 691.19, train acc: 0.9925, val loss: 1373.15, val acc: 0.9636, time: 244.50s\n",
            "Epoch:16, Training loss: 611.37, train acc: 0.9937, val loss: 1392.26, val acc: 0.9615, time: 245.05s\n",
            "Epoch:17, Training loss: 549.79, train acc: 0.9958, val loss: 1309.53, val acc: 0.9665, time: 241.42s\n",
            "Epoch:18, Training loss: 497.22, train acc: 0.9954, val loss: 1449.04, val acc: 0.9637, time: 241.81s\n",
            "Epoch:19, Training loss: 432.74, train acc: 0.9959, val loss: 1550.87, val acc: 0.9639, time: 248.09s\n",
            "Epoch:20, Training loss: 372.63, train acc: 0.9978, val loss: 1390.30, val acc: 0.9657, time: 244.82s\n",
            "Epoch:21, Training loss: 372.22, train acc: 0.9984, val loss: 1460.39, val acc: 0.9661, time: 244.48s\n",
            "Epoch:22, Training loss: 309.29, train acc: 0.9983, val loss: 1427.43, val acc: 0.9677, time: 243.04s\n",
            "Epoch:23, Training loss: 356.65, train acc: 0.9978, val loss: 1534.47, val acc: 0.9668, time: 243.22s\n",
            "Epoch:24, Training loss: 300.18, train acc: 0.9992, val loss: 1495.79, val acc: 0.9690, time: 246.38s\n",
            "Epoch:25, Training loss: 286.97, train acc: 0.9992, val loss: 1514.57, val acc: 0.9670, time: 242.36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zrV9XwD0wTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "64cad0c2-378a-43b2-d336-8a63b6fbe942"
      },
      "source": [
        "### save model \n",
        "torch.save(model, '/content/gdrive/My Drive/COMP5046/model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt_Z58EGIkgT",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBg13xgaIjls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bd830474-29e5-45de-8bb0-61de920dd35b"
      },
      "source": [
        "%%time \n",
        "### evaluating the model on the validation set. \n",
        "y_true, y_pred, _ =  cal_acc(model, valid_input_dict, valid_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    idx_to_tag = {v:k for k,v in tag_to_idx.items()}\n",
        "    return [idx_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)\n",
        "print(len(y_true_decode), len(y_pred_decode))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556 7556\n",
            "CPU times: user 7.21 s, sys: 155 ms, total: 7.36 s\n",
            "Wall time: 7.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fMBqBgeInlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fd7f5465-3de0-48b8-f251-3ffc51cdb194"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.9121    0.9165    0.9143       419\n",
            "      I-MISC     0.8430    0.7754    0.8078       187\n",
            "       I-ORG     0.8192    0.7474    0.7817       285\n",
            "       I-PER     0.9742    0.9497    0.9618       875\n",
            "           O     0.9814    0.9915    0.9864      5790\n",
            "\n",
            "    accuracy                         0.9680      7556\n",
            "   macro avg     0.9060    0.8761    0.8904      7556\n",
            "weighted avg     0.9672    0.9680    0.9674      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWS_xdbPHN1S",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a2i_UqyPdOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_predictions(model, input_dict): \n",
        "    \"\"\"\n",
        "    Function to get the kaggle prediction on the test set. \n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(0, len(input_dict['sentence'])): \n",
        "        input = unpack_features(i, input_dict)\n",
        "        pred_idxs = model(input)[1]\n",
        "        pred = decode_output(pred_idxs)\n",
        "        predictions += pred\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrl6c3tRQ4lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6a43eab-51d1-4ee3-8cd8-bec3e279d2ef"
      },
      "source": [
        "%%time \n",
        "predictions = get_test_predictions(model, test_input_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 42.9 s, sys: 856 ms, total: 43.8 s\n",
            "Wall time: 43.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahj0lH7zQdnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_submission = pd.DataFrame.from_dict({'ID': np.arange(0, len(predictions)), 'Predicted': predictions})\n",
        "kaggle_submission.to_csv('submission.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKgHt7Q6Q1Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f2d3d3be-1a24-4c58-9e8b-0679513eca1b"
      },
      "source": [
        "kaggle_submission "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46661</th>\n",
              "      <td>46661</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46662</th>\n",
              "      <td>46662</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46663</th>\n",
              "      <td>46663</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46664</th>\n",
              "      <td>46664</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46665</th>\n",
              "      <td>46665</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46666 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID Predicted\n",
              "0          0         O\n",
              "1          1         O\n",
              "2          2         O\n",
              "3          3     I-LOC\n",
              "4          4         O\n",
              "...      ...       ...\n",
              "46661  46661         O\n",
              "46662  46662         O\n",
              "46663  46663         O\n",
              "46664  46664     I-PER\n",
              "46665  46665         O\n",
              "\n",
              "[46666 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}